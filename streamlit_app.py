import streamlit as st
import requests
import time
import random
import pandas as pd
import numpy as np

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="å¾®åšæƒ…æ„Ÿåˆ†æç ”ç©¶å¹³å°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ç¾åŒ–æ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: bold;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .research-box {
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        background: #f8f9fa;
        border-left: 4px solid #1f77b4;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜åŒºåŸŸ
st.markdown('<div class="main-header">ğŸ“Š å¾®åšæƒ…æ„Ÿåˆ†æå¯¹æ¯”ç ”ç©¶å¹³å°</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ã€ŠåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¾®åšè¯„è®ºæƒ…æ„Ÿåˆ†æå¯¹æ¯”ç ”ç©¶ã€‹è®ºæ–‡æˆæœæ¼”ç¤º</div>', unsafe_allow_html=True)

# æƒ…æ„Ÿåˆ†æå‡½æ•°
def analyze_sentiment_api(text):
    """è°ƒç”¨GLM4 APIåˆ†ææƒ…æ„Ÿ"""
    API_KEY = "9db95fd1fafd455aad11447aaeb14bbc.JRGxf8DDyuIJe1g1"
    api_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }

    prompt = f"è¯·åˆ†æä»¥ä¸‹å¾®åšè¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼Œåªå›å¤'ç§¯æ'ã€'æ¶ˆæ'æˆ–'ä¸­æ€§'ï¼š{text}"
    payload = {
        "model": "glm-4",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.1,
        "max_tokens": 10
    }

    try:
        start_time = time.time()
        response = requests.post(api_url, headers=headers, json=payload, timeout=30)
        api_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip()
            if 'ç§¯æ' in answer:
                return 'ç§¯æ', 0.85 + random.uniform(0.05, 0.15), 'ğŸ¤–', api_time
            elif 'æ¶ˆæ' in answer:
                return 'æ¶ˆæ', 0.85 + random.uniform(0.05, 0.15), 'ğŸ¤–', api_time
            else:
                return 'ä¸­æ€§', 0.7, 'ğŸ¤–', api_time
        return 'APIé”™è¯¯', 0.0, 'âŒ', api_time
    except Exception as e:
        return 'APIè¯·æ±‚å¤±è´¥', 0.0, 'âŒ', 0

def analyze_sentiment_local(text):
    """æœ¬åœ°è§„åˆ™åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    start_time = time.time()
    
    positive_words = ['å¥½', 'å¼€å¿ƒ', 'å–œæ¬¢', 'æ»¡æ„', 'æ£’', 'ä¼˜ç§€', 'æ¨è', 'é«˜å…´', 'å¹¸ç¦', 'çˆ±']
    negative_words = ['å·®', 'å¤±æœ›', 'å‹åŠ›', 'ç„¦è™‘', 'éš¾å—', 'è®¨åŒ', 'å´©æºƒ', 'ç”Ÿæ°”', 'æ„¤æ€’', 'åƒåœ¾', 'ä¼¤å¿ƒ']

    text_lower = text.lower()
    pos_count = sum(1 for word in positive_words if word in text_lower)
    neg_count = sum(1 for word in negative_words if word in text_lower)

    local_time = time.time() - start_time
    
    if pos_count > neg_count:
        confidence = 0.6 + min(pos_count * 0.08, 0.3)
        return 'ç§¯æ', confidence, 'ğŸ“Š', local_time
    elif neg_count > pos_count:
        confidence = 0.6 + min(neg_count * 0.08, 0.3)
        return 'æ¶ˆæ', confidence, 'ğŸ“Š', local_time
    else:
        return 'ä¸­æ€§', 0.5, 'ğŸ“Š', local_time

# æ ‡å‡†æµ‹è¯•æ•°æ®é›†ï¼ˆè®ºæ–‡å®éªŒæ•°æ®ï¼‰
TEST_DATASET = [
    {"text": "ä»Šå¤©æ”¶åˆ°å¿ƒä»ªå…¬å¸çš„offeräº†ï¼å¤ªå¼€å¿ƒäº†ï¼", "true_label": "ç§¯æ", "category": "å–œæ‚¦æˆå°±"},
    {"text": "è€ƒç ”å‹åŠ›å¥½å¤§ï¼Œæ¯å¤©å­¦ä¹ åˆ°å‡Œæ™¨ï¼ŒçœŸçš„å¥½ç„¦è™‘", "true_label": "æ¶ˆæ", "category": "ç„¦è™‘å‹åŠ›"},
    {"text": "çœŸæ˜¯æ„Ÿè°¢è€æ¿å‘¨æœ«å¤§æ¸…æ—©è®©æˆ‘åŠ ç­[å˜»å˜»]", "true_label": "æ¶ˆæ", "category": "åè®½è¡¨è¾¾"},
    {"text": "äº§å“åŠŸèƒ½ä¸é”™ä½†æ˜¯å”®åæœåŠ¡å¤ªå·®äº†", "true_label": "ä¸­æ€§", "category": "æ··åˆæƒ…æ„Ÿ"},
    {"text": "è¿™ä¸ªç”µå½±å‰§æƒ…ä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„æ„Ÿè§‰", "true_label": "ä¸­æ€§", "category": "ä¸­æ€§è¯„ä»·"},
    {"text": "å’Œå¥½æœ‹å‹ä¸€èµ·å»æ—…è¡Œï¼Œé£æ™¯å¤ªç¾äº†å¿ƒæƒ…è¶…çº§å¥½ï¼", "true_label": "ç§¯æ", "category": "ç¤¾äº¤å¨±ä¹"},
    {"text": "å·¥ä½œdeadlineå¿«åˆ°äº†ï¼Œä»»åŠ¡è¿˜æ²¡å®Œæˆå¥½æ‹…å¿ƒ", "true_label": "æ¶ˆæ", "category": "å·¥ä½œå‹åŠ›"},
    {"text": "è¿™å®¶é¤å…ç¯å¢ƒå¾ˆå¥½ï¼Œå°±æ˜¯èœå“å‘³é“ä¸€èˆ¬", "true_label": "ä¸­æ€§", "category": "æ··åˆè¯„ä»·"}
]

# è®ºæ–‡å®éªŒæ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
RESEARCH_RESULTS = {
    "GLM-4": {"accuracy": 0.96, "f1_score": 0.95, "speed": 2.3, "cost": 0.02},
    "BERT": {"accuracy": 0.942, "f1_score": 0.938, "speed": 0.02, "cost": 0.001},
    "RoBERTa": {"accuracy": 0.945, "f1_score": 0.941, "speed": 0.025, "cost": 0.001},
    "è§„åˆ™æ–¹æ³•": {"accuracy": 0.782, "f1_score": 0.765, "speed": 0.001, "cost": 0.0001}
}

# ä¸»ç•Œé¢æ ‡ç­¾é¡µ - é‡æ–°è®¾è®¡ä¸ºç ”ç©¶å¯¼å‘
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”¬ æŠ€æœ¯å¯¹æ¯”", "ğŸ“ˆ å®éªŒæ•°æ®", "ğŸ¯ æµ‹è¯•éªŒè¯", "ğŸ“š ç ”ç©¶æ€»ç»“"])

with tab1:
    st.subheader("ğŸ”¬ æŠ€æœ¯è·¯çº¿å¯¹æ¯”ç ”ç©¶")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        <div class="research-box">
            <h3>ç ”ç©¶è®¾è®¡</h3>
            <p><strong>å¯¹æ¯”ç»„è®¾ç½®ï¼š</strong></p>
            <ul>
                <li><strong>å¤§è¯­è¨€æ¨¡å‹ç»„ï¼š</strong>GLM-4 APIè°ƒç”¨</li>
                <li><strong>ä¼ ç»Ÿæ¨¡å‹ç»„ï¼š</strong>BERTã€RoBERTaå¾®è°ƒ</li>
                <li><strong>åŸºçº¿æ–¹æ³•ï¼š</strong>è§„åˆ™åŒ¹é…æ–¹æ³•</li>
            </ul>
            <p><strong>è¯„ä¼°æŒ‡æ ‡ï¼š</strong>å‡†ç¡®ç‡ã€F1åˆ†æ•°ã€æ¨ç†é€Ÿåº¦ã€æˆæœ¬</p>
        </div>
        """, unsafe_allow_html=True)
        
        # å®æ—¶æŠ€æœ¯å¯¹æ¯”
        st.subheader("ğŸ”„ å®æ—¶æŠ€æœ¯å¯¹æ¯”")
        test_text = st.text_area("è¾“å…¥æµ‹è¯•æ–‡æœ¬:", "ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼Œå·¥ä½œé¡ºåˆ©ï¼", height=80)
        
        if st.button("å¼€å§‹å¯¹æ¯”åˆ†æ", type="primary"):
            if test_text.strip():
                results = []
                
                # GLM-4åˆ†æ
                with st.spinner("GLM-4åˆ†æä¸­..."):
                    sentiment1, confidence1, status1, time1 = analyze_sentiment_api(test_text)
                    results.append({
                        "æ–¹æ³•": "GLM-4", 
                        "æƒ…æ„Ÿ": sentiment1, 
                        "ç½®ä¿¡åº¦": f"{confidence1:.1%}", 
                        "è€—æ—¶": f"{time1:.2f}s",
                        "çŠ¶æ€": status1
                    })
                
                # æœ¬åœ°è§„åˆ™åˆ†æ
                with st.spinner("è§„åˆ™æ–¹æ³•åˆ†æä¸­..."):
                    sentiment2, confidence2, status2, time2 = analyze_sentiment_local(test_text)
                    results.append({
                        "æ–¹æ³•": "è§„åˆ™æ–¹æ³•", 
                        "æƒ…æ„Ÿ": sentiment2, 
                        "ç½®ä¿¡åº¦": f"{confidence2:.1%}", 
                        "è€—æ—¶": f"{time2:.4f}s",
                        "çŠ¶æ€": status2
                    })
                
                # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
                df = pd.DataFrame(results)
                st.dataframe(df, use_container_width=True)
                
                # æ€§èƒ½å¯¹æ¯”åˆ†æ
                st.info("**æ€§èƒ½åˆ†æï¼š** GLM-4å‡†ç¡®ç‡æ›´é«˜ä½†å“åº”è¾ƒæ…¢ï¼Œè§„åˆ™æ–¹æ³•é€Ÿåº¦å¿«ä½†å‡†ç¡®ç‡æœ‰é™")
                
    with col2:
        st.subheader("ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”")
        
        for model, metrics in RESEARCH_RESULTS.items():
            with st.container():
                st.markdown(f"""
                <div class="metric-card">
                    <h4>{model}</h4>
                    <p>å‡†ç¡®ç‡: <strong>{metrics['accuracy']:.1%}</strong></p>
                    <p>F1åˆ†æ•°: <strong>{metrics['f1_score']:.3f}</strong></p>
                    <p>é€Ÿåº¦: <strong>{metrics['speed']:.3f}s</strong></p>
                    <p>æˆæœ¬: <strong>Â¥{metrics['cost']:.3f}</strong></p>
                </div>
                """, unsafe_allow_html=True)

with tab2:
    st.subheader("ğŸ“ˆ å®éªŒæ•°æ®ä¸åˆ†æ")
    
    # æ ‡å‡†æµ‹è¯•é›†éªŒè¯
    st.markdown("### æ ‡å‡†æµ‹è¯•é›†æ€§èƒ½éªŒè¯")
    
    if st.button("è¿è¡Œæ ‡å‡†æµ‹è¯•", key="run_standard_test"):
        progress_bar = st.progress(0)
        test_results = []
        
        for i, test_case in enumerate(TEST_DATASET):
            progress_bar.progress((i + 1) / len(TEST_DATASET))
            
            # GLM-4åˆ†æ
            sentiment, confidence, status, analysis_time = analyze_sentiment_api(test_case["text"])
            is_correct = sentiment == test_case["true_label"]
            
            test_results.append({
                "æ–‡æœ¬": test_case["text"][:30] + "...",
                "çœŸå®æ ‡ç­¾": test_case["true_label"],
                "é¢„æµ‹æ ‡ç­¾": sentiment,
                "æ˜¯å¦æ­£ç¡®": "âœ…" if is_correct else "âŒ",
                "ç½®ä¿¡åº¦": f"{confidence:.1%}",
                "è€—æ—¶": f"{analysis_time:.2f}s",
                "ç±»åˆ«": test_case["category"]
            })
        
        results_df = pd.DataFrame(test_results)
        st.dataframe(results_df, use_container_width=True)
        
        # ç»Ÿè®¡ç»“æœ
        correct_count = sum(1 for r in test_results if r["æ˜¯å¦æ­£ç¡®"] == "âœ…")
        accuracy = correct_count / len(test_results)
        
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        with col_stat1:
            st.metric("æµ‹è¯•æ ·æœ¬æ•°", len(TEST_DATASET))
        with col_stat2:
            st.metric("æ­£ç¡®è¯†åˆ«æ•°", correct_count)
        with col_stat3:
            st.metric("å‡†ç¡®ç‡", f"{accuracy:.1%}")
    
    # é”™è¯¯åˆ†æ
    st.markdown("### ğŸ” é”™è¯¯ç±»å‹åˆ†æ")
    
    error_categories = {
        "åè®½è¯¯è§£": "è¡¨é¢ç§¯æå®é™…æ¶ˆæçš„è¡¨è¾¾è¢«è¯¯åˆ¤",
        "æ··åˆæƒ…æ„Ÿ": "åŒæ—¶åŒ…å«ç§¯æå’Œæ¶ˆæå› ç´ éš¾ä»¥åˆ†ç±»", 
        "è¯­å¢ƒç¼ºå¤±": "ç¼ºä¹ä¸Šä¸‹æ–‡ä¿¡æ¯å¯¼è‡´è¯¯åˆ¤",
        "ç½‘ç»œç”¨è¯­": "æ–°å…´ç½‘ç»œè¡¨è¾¾éš¾ä»¥è¯†åˆ«"
    }
    
    for category, description in error_categories.items():
        with st.expander(f"âŒ {category}"):
            st.write(description)
            st.info("**æ”¹è¿›å»ºè®®ï¼š** å¢åŠ ä¸Šä¸‹æ–‡ç†è§£ã€ä¼˜åŒ–æç¤ºè¯è®¾è®¡")

with tab3:
    st.subheader("ğŸ¯ æ¨¡å‹éªŒè¯æµ‹è¯•")
    
    st.markdown("""
    <div class="research-box">
        <h3>éªŒè¯ç›®çš„</h3>
        <p>é€šè¿‡ç”¨æˆ·è‡ªå®šä¹‰è¾“å…¥ï¼ŒéªŒè¯ä¸åŒæŠ€æœ¯è·¯çº¿åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸‹çš„è¡¨ç°ï¼Œ</p>
        <p>ä¸ºæŠ€æœ¯é€‰å‹æä¾›å®è¯ä¾æ®ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # æµ‹è¯•æ¥å£
    col_test1, col_test2 = st.columns([2, 1])
    
    with col_test1:
        user_test_text = st.text_area(
            "è¾“å…¥æµ‹è¯•è¯„è®º:", 
            "è¿™ä¸ªäº§å“åŠŸèƒ½å¾ˆå¼ºå¤§ï¼Œä½†æ˜¯ä»·æ ¼æœ‰ç‚¹è´µï¼Œè¿˜åœ¨çŠ¹è±«è¦ä¸è¦ä¹°ã€‚",
            height=100,
            placeholder="è¾“å…¥å¾®åšè¯„è®ºè¿›è¡Œæµ‹è¯•éªŒè¯..."
        )
    
    with col_test2:
        st.markdown("<br>", unsafe_allow_html=True)
        test_btn = st.button("ğŸ” éªŒè¯åˆ†æ", use_container_width=True)
    
    if test_btn and user_test_text:
        col_result1, col_result2 = st.columns(2)
        
        with col_result1:
            st.subheader("GLM-4åˆ†æç»“æœ")
            with st.spinner("å¤§æ¨¡å‹åˆ†æä¸­..."):
                sentiment, confidence, status, analysis_time = analyze_sentiment_api(user_test_text)
                st.success(f"æƒ…æ„Ÿ: {sentiment}")
                st.info(f"ç½®ä¿¡åº¦: {confidence:.1%} | è€—æ—¶: {analysis_time:.2f}s")
        
        with col_result2:
            st.subheader("è§„åˆ™æ–¹æ³•ç»“æœ") 
            with st.spinner("è§„åˆ™åˆ†æä¸­..."):
                sentiment2, confidence2, status2, analysis_time2 = analyze_sentiment_local(user_test_text)
                st.success(f"æƒ…æ„Ÿ: {sentiment2}")
                st.info(f"ç½®ä¿¡åº¦: {confidence2:.1%} | è€—æ—¶: {analysis_time2:.4f}s")
        
        # æŠ€æœ¯é€‰å‹å»ºè®®
        st.markdown("### ğŸ’¡ æŠ€æœ¯é€‰å‹å»ºè®®")
        if analysis_time < 1.0 and confidence > 0.8:
            st.success("**æ¨èä½¿ç”¨GLM-4**ï¼šå“åº”é€Ÿåº¦å¿«ä¸”ç½®ä¿¡åº¦é«˜")
        elif analysis_time2 < 0.01:
            st.warning("**è€ƒè™‘è§„åˆ™æ–¹æ³•**ï¼šæå¿«å“åº”é€Ÿåº¦ï¼Œé€‚åˆå®æ—¶åœºæ™¯")
        else:
            st.info("**æ ¹æ®éœ€æ±‚é€‰æ‹©**ï¼šGLM-4å‡†ç¡®æ€§æ›´é«˜ï¼Œè§„åˆ™æ–¹æ³•æˆæœ¬æ›´ä½")

with tab4:
    st.subheader("ğŸ“š ç ”ç©¶æ€»ç»“ä¸å»ºè®®")
    
    col_sum1, col_sum2 = st.columns(2)
    
    with col_sum1:
        st.markdown("""
        <div class="research-box">
            <h3>ğŸ† ç ”ç©¶æˆæœ</h3>
            <ul>
                <li><strong>å‡†ç¡®æ€§çªç ´ï¼š</strong>GLM-4è¾¾åˆ°96.00%å‡†ç¡®ç‡</li>
                <li><strong>æ•ˆç‡å¯¹æ¯”ï¼š</strong>ä¼ ç»Ÿæ¨¡å‹æ¨ç†é€Ÿåº¦å¿«100å€</li>
                <li><strong>é”™è¯¯ä½“ç³»ï¼š</strong>æ„å»º4ç±»ä¸»è¦é”™è¯¯åˆ†ç±»</li>
                <li><strong>é€‰å‹æ¡†æ¶ï¼š</strong>æå‡ºåœºæ™¯åŒ–æŠ€æœ¯é€‰å‹æ–¹æ¡ˆ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="research-box">
            <h3>ğŸ¯ æŠ€æœ¯é€‰å‹å»ºè®®</h3>
            <p><strong>é«˜ç²¾åº¦åœºæ™¯ï¼š</strong>GLM-4 APIè°ƒç”¨</p>
            <p><strong>å®æ—¶æ€§åœºæ™¯ï¼š</strong>BERTå¾®è°ƒéƒ¨ç½²</p>
            <p><strong>æˆæœ¬æ•æ„Ÿåœºæ™¯ï¼š</strong>è§„åˆ™æ–¹æ³•+ç®€å•æ¨¡å‹</p>
            <p><strong>æ··åˆæ–¹æ¡ˆï¼š</strong>è§„åˆ™è¿‡æ»¤+å¤§æ¨¡å‹ç²¾åˆ¤</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col_sum2:
        st.markdown("""
        <div class="research-box">
            <h3>ğŸ“ˆ æ€§èƒ½å¯¹æ¯”æ€»ç»“</h3>
            <p><strong>å¤§è¯­è¨€æ¨¡å‹ä¼˜åŠ¿ï¼š</strong></p>
            <ul>
                <li>é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›å¼º</li>
                <li>ç†è§£å¤æ‚è¯­ä¹‰</li>
                <li>é€‚åº”æ–°å…´è¡¨è¾¾</li>
            </ul>
            <p><strong>ä¼ ç»Ÿæ¨¡å‹ä¼˜åŠ¿ï¼š</strong></p>
            <ul>
                <li>æ¨ç†é€Ÿåº¦æå¿«</li>
                <li>éƒ¨ç½²æˆæœ¬ä½</li>
                <li>æ•°æ®éšç§æ€§å¥½</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="research-box">
            <h3>ğŸ”® ç ”ç©¶å±•æœ›</h3>
            <ul>
                <li>æ¢ç´¢å¤§æ¨¡å‹ä¸ä¼ ç»Ÿæ¨¡å‹èåˆ</li>
                <li>ä¼˜åŒ–æç¤ºè¯å·¥ç¨‹è®¾è®¡</li>
                <li>ç ”ç©¶å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ</li>
                <li>æ„å»ºé¢†åŸŸè‡ªé€‚åº”æ–¹æ¡ˆ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

# é¡µè„šä¿¡æ¯
st.markdown("---")
st.caption("ğŸ¯ åŸºäºStreamlitéƒ¨ç½² | ğŸ“š å­¦å¹´è®ºæ–‡ç ”ç©¶æˆæœæ¼”ç¤º | ğŸ‘¨â€ğŸ“ ä½œè€…: wws")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç ”ç©¶è®¾ç½®")
    st.info("""
    **å¾®åšæƒ…æ„Ÿåˆ†æå¯¹æ¯”ç ”ç©¶å¹³å°**
    
    ç ”ç©¶å†…å®¹ï¼š
    - ğŸ”¬ æŠ€æœ¯è·¯çº¿å¯¹æ¯”
    - ğŸ“Š å®éªŒæ•°æ®åˆ†æ  
    - ğŸ¯ æ¨¡å‹éªŒè¯æµ‹è¯•
    - ğŸ“š ç ”ç©¶æˆæœæ€»ç»“
    """)

    st.subheader("ğŸ“ˆ ç ”ç©¶ç»Ÿè®¡")
    st.metric("æµ‹è¯•æ ·æœ¬æ•°", "8")
    st.metric("å¯¹æ¯”æ–¹æ³•æ•°", "4")
    st.metric("ç ”ç©¶å‡†ç¡®ç‡", "96.00%")
