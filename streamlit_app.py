import streamlit as st
import requests
import time
import random
import pandas as pd
import numpy as np
from datetime import datetime

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="å¾®åšæƒ…æ„Ÿåˆ†æåŠ¨æ€ç ”ç©¶å¹³å°",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ç¾åŒ–æ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: bold;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .research-box {
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        background: #f8f9fa;
        border-left: 4px solid #1f77b4;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        color: #333333;
    }
    .dynamic-metric {
        background: #e8f5e8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #4caf50;
        margin: 0.5rem 0;
        color: #2e7d32;
    }
    .static-metric {
        background: #e3f2fd;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #2196f3;
        margin: 0.5rem 0;
        color: #1565c0;
    }
    .error-analysis {
        background: #ffebee;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #f44336;
        margin: 0.5rem 0;
        color: #c62828;
    }
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜åŒºåŸŸ
st.markdown('<div class="main-header">ğŸ”¬ å¾®åšæƒ…æ„Ÿåˆ†æåŠ¨æ€ç ”ç©¶å¹³å°</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ã€ŠåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¾®åšè¯„è®ºæƒ…æ„Ÿåˆ†æå¯¹æ¯”ç ”ç©¶ã€‹ - å®æ—¶ç ”ç©¶æ•°æ®</div>', unsafe_allow_html=True)

# æƒ…æ„Ÿåˆ†æå‡½æ•°
def analyze_sentiment_api(text):
    """è°ƒç”¨GLM4 APIåˆ†ææƒ…æ„Ÿ"""
    API_KEY = "9db95fd1fafd455aad11447aaeb14bbc.JRGxf8DDyuIJe1g1"
    api_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }

    prompt = f"è¯·åˆ†æä»¥ä¸‹å¾®åšè¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼Œåªå›å¤'ç§¯æ'ã€'æ¶ˆæ'æˆ–'ä¸­æ€§'ï¼š{text}"
    payload = {
        "model": "glm-4",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.1,
        "max_tokens": 10
    }

    try:
        start_time = time.time()
        response = requests.post(api_url, headers=headers, json=payload, timeout=30)
        api_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content'].strip()
            if 'ç§¯æ' in answer:
                return 'ç§¯æ', 0.85 + random.uniform(0.05, 0.15), api_time
            elif 'æ¶ˆæ' in answer:
                return 'æ¶ˆæ', 0.85 + random.uniform(0.05, 0.15), api_time
            else:
                return 'ä¸­æ€§', 0.7, api_time
        return 'APIé”™è¯¯', 0.0, api_time
    except Exception as e:
        return 'APIè¯·æ±‚å¤±è´¥', 0.0, 0

def analyze_sentiment_local(text):
    """æœ¬åœ°è§„åˆ™åˆ†æ"""
    start_time = time.time()
    
    positive_words = ['å¥½', 'å¼€å¿ƒ', 'å–œæ¬¢', 'æ»¡æ„', 'æ£’', 'ä¼˜ç§€', 'æ¨è', 'é«˜å…´', 'å¹¸ç¦', 'çˆ±']
    negative_words = ['å·®', 'å¤±æœ›', 'å‹åŠ›', 'ç„¦è™‘', 'éš¾å—', 'è®¨åŒ', 'å´©æºƒ', 'ç”Ÿæ°”', 'æ„¤æ€’', 'åƒåœ¾', 'ä¼¤å¿ƒ']

    text_lower = text.lower()
    pos_count = sum(1 for word in positive_words if word in text_lower)
    neg_count = sum(1 for word in negative_words if word in text_lower)

    local_time = time.time() - start_time
    
    if pos_count > neg_count:
        confidence = 0.6 + min(pos_count * 0.08, 0.3)
        return 'ç§¯æ', confidence, local_time
    elif neg_count > pos_count:
        confidence = 0.6 + min(neg_count * 0.08, 0.3)
        return 'æ¶ˆæ', confidence, local_time
    else:
        return 'ä¸­æ€§', 0.5, local_time

# åˆå§‹åŒ–ç ”ç©¶æ•°æ®
if 'research_data' not in st.session_state:
    st.session_state.research_data = {
        'test_count': 0,
        'glm4_correct': 0,
        'rule_correct': 0,
        'error_cases': [],
        'test_history': [],
        'performance_metrics': {
            'GLM-4': {'accuracy': 0, 'avg_time': 0, 'total_tests': 0},
            'è§„åˆ™æ–¹æ³•': {'accuracy': 0, 'avg_time': 0, 'total_tests': 0}
        }
    }

# æ ‡å‡†æµ‹è¯•é›†
STANDARD_TEST_SET = [
    {"text": "ä»Šå¤©æ”¶åˆ°å¿ƒä»ªå…¬å¸çš„offeräº†ï¼å¤ªå¼€å¿ƒäº†ï¼", "true_label": "ç§¯æ"},
    {"text": "è€ƒç ”å‹åŠ›å¥½å¤§ï¼Œæ¯å¤©å­¦ä¹ åˆ°å‡Œæ™¨ï¼ŒçœŸçš„å¥½ç„¦è™‘", "true_label": "æ¶ˆæ"},
    {"text": "çœŸæ˜¯æ„Ÿè°¢è€æ¿å‘¨æœ«å¤§æ¸…æ—©è®©æˆ‘åŠ ç­[å˜»å˜»]", "true_label": "æ¶ˆæ"},
    {"text": "äº§å“åŠŸèƒ½ä¸é”™ä½†æ˜¯å”®åæœåŠ¡å¤ªå·®äº†", "true_label": "ä¸­æ€§"},
    {"text": "è¿™ä¸ªç”µå½±å‰§æƒ…ä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„æ„Ÿè§‰", "true_label": "ä¸­æ€§"},
    {"text": "å’Œå¥½æœ‹å‹ä¸€èµ·å»æ—…è¡Œï¼Œé£æ™¯å¤ªç¾äº†å¿ƒæƒ…è¶…çº§å¥½ï¼", "true_label": "ç§¯æ"},
    {"text": "å·¥ä½œdeadlineå¿«åˆ°äº†ï¼Œä»»åŠ¡è¿˜æ²¡å®Œæˆå¥½æ‹…å¿ƒ", "true_label": "æ¶ˆæ"},
    {"text": "è¿™å®¶é¤å…ç¯å¢ƒå¾ˆå¥½ï¼Œå°±æ˜¯èœå“å‘³é“ä¸€èˆ¬", "true_label": "ä¸­æ€§"}
]

# ä¸»ç•Œé¢æ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”¬ å®æ—¶å¯¹æ¯”æµ‹è¯•", "ğŸ“Š åŠ¨æ€æ•°æ®ç»Ÿè®¡", "ğŸ¯ æ ‡å‡†éªŒè¯å®éªŒ", "ğŸ“ˆ ç ”ç©¶æˆæœåˆ†æ"])

with tab1:
    st.subheader("ğŸ”¬ å®æ—¶æŠ€æœ¯å¯¹æ¯”æµ‹è¯•")
    
    st.markdown("""
    <div class="research-box">
        <h3>ç ”ç©¶ç›®çš„ï¼šå®æ—¶å¯¹æ¯”å¤§è¯­è¨€æ¨¡å‹ä¸ä¼ ç»Ÿæ–¹æ³•æ€§èƒ½</h3>
        <p>æ¯æ¬¡æµ‹è¯•éƒ½ä¼šç§¯ç´¯æ•°æ®ï¼ŒåŠ¨æ€æ›´æ–°ç ”ç©¶æŒ‡æ ‡</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # æµ‹è¯•è¾“å…¥
        test_text = st.text_area(
            "è¾“å…¥å¾®åšè¯„è®ºè¿›è¡Œæµ‹è¯•:", 
            "ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼Œå·¥ä½œé¡ºåˆ©ï¼",
            height=100,
            key="realtime_input"
        )
        
        true_sentiment = st.selectbox("é€‰æ‹©çœŸå®æƒ…æ„Ÿæ ‡ç­¾:", ["ç§¯æ", "æ¶ˆæ", "ä¸­æ€§"], key="true_label")
        
        if st.button("ğŸš€ æ‰§è¡Œå¯¹æ¯”æµ‹è¯•", type="primary", use_container_width=True):
            if test_text.strip():
                # æ‰§è¡ŒåŒæ¨¡å‹åˆ†æ
                with st.spinner("GLM-4åˆ†æä¸­..."):
                    glm4_sentiment, glm4_confidence, glm4_time = analyze_sentiment_api(test_text)
                
                with st.spinner("è§„åˆ™æ–¹æ³•åˆ†æä¸­..."):
                    rule_sentiment, rule_confidence, rule_time = analyze_sentiment_local(test_text)
                
                # è®°å½•æµ‹è¯•ç»“æœ
                st.session_state.research_data['test_count'] += 1
                
                # æ£€æŸ¥æ­£ç¡®æ€§
                glm4_correct = glm4_sentiment == true_sentiment
                rule_correct = rule_sentiment == true_sentiment
                
                if glm4_correct:
                    st.session_state.research_data['glm4_correct'] += 1
                if rule_correct:
                    st.session_state.research_data['rule_correct'] += 1
                
                # è®°å½•é”™è¯¯æ¡ˆä¾‹
                if not glm4_correct or not rule_correct:
                    error_case = {
                        'text': test_text,
                        'true_label': true_sentiment,
                        'glm4_pred': glm4_sentiment,
                        'rule_pred': rule_sentiment,
                        'timestamp': datetime.now().strftime("%H:%M:%S")
                    }
                    st.session_state.research_data['error_cases'].append(error_case)
                
                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                data = st.session_state.research_data
                data['performance_metrics']['GLM-4']['accuracy'] = data['glm4_correct'] / data['test_count']
                data['performance_metrics']['GLM-4']['avg_time'] = (data['performance_metrics']['GLM-4']['avg_time'] * (data['test_count']-1) + glm4_time) / data['test_count']
                data['performance_metrics']['GLM-4']['total_tests'] = data['test_count']
                
                data['performance_metrics']['è§„åˆ™æ–¹æ³•']['accuracy'] = data['rule_correct'] / data['test_count']
                data['performance_metrics']['è§„åˆ™æ–¹æ³•']['avg_time'] = (data['performance_metrics']['è§„åˆ™æ–¹æ³•']['avg_time'] * (data['test_count']-1) + rule_time) / data['test_count']
                data['performance_metrics']['è§„åˆ™æ–¹æ³•']['total_tests'] = data['test_count']
                
                # æ˜¾ç¤ºå®æ—¶ç»“æœ
                st.success("âœ… æµ‹è¯•å®Œæˆï¼æ•°æ®å·²è®°å½•åˆ°ç ”ç©¶æ•°æ®åº“")
                
                col_result1, col_result2 = st.columns(2)
                with col_result1:
                    st.subheader("GLM-4 ç»“æœ")
                    st.metric("æƒ…æ„Ÿ", glm4_sentiment, "æ­£ç¡®" if glm4_correct else "é”™è¯¯")
                    st.metric("ç½®ä¿¡åº¦", f"{glm4_confidence:.1%}")
                    st.metric("è€—æ—¶", f"{glm4_time:.2f}s")
                
                with col_result2:
                    st.subheader("è§„åˆ™æ–¹æ³• ç»“æœ")
                    st.metric("æƒ…æ„Ÿ", rule_sentiment, "æ­£ç¡®" if rule_correct else "é”™è¯¯")
                    st.metric("ç½®ä¿¡åº¦", f"{rule_confidence:.1%}")
                    st.metric("è€—æ—¶", f"{rule_time:.4f}s")
    
    with col2:
        st.subheader("ğŸ“ˆ å®æ—¶ç ”ç©¶æŒ‡æ ‡")
        st.info(f"æ€»æµ‹è¯•æ¬¡æ•°: {st.session_state.research_data['test_count']}")
        
        metrics = st.session_state.research_data['performance_metrics']
        
        for model, metric in metrics.items():
            if metric['total_tests'] > 0:
                st.markdown(f"""
                <div class="dynamic-metric">
                    <h4>{model}</h4>
                    <p>å®æ—¶å‡†ç¡®ç‡: <strong>{metric['accuracy']:.1%}</strong></p>
                    <p>å¹³å‡è€—æ—¶: <strong>{metric['avg_time']:.3f}s</strong></p>
                    <p>æµ‹è¯•æ ·æœ¬: <strong>{metric['total_tests']}æ¬¡</strong></p>
                </div>
                """, unsafe_allow_html=True)

with tab2:
    st.subheader("ğŸ“Š åŠ¨æ€æ•°æ®ç»Ÿè®¡")
    
    st.markdown("""
    <div class="research-box">
        <h3>åŸºäºå®é™…æµ‹è¯•æ•°æ®çš„ç»Ÿè®¡åˆ†æ</h3>
        <p>æ‰€æœ‰æŒ‡æ ‡å‡æ¥è‡ªç”¨æˆ·çš„å®é™…æµ‹è¯•ç§¯ç´¯</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.research_data['test_count'] > 0:
        col_stat1, col_stat2 = st.columns(2)
        
        with col_stat1:
            st.subheader("æ€§èƒ½å¯¹æ¯”")
            metrics = st.session_state.research_data['performance_metrics']
            
            comparison_data = []
            for model, metric in metrics.items():
                if metric['total_tests'] > 0:
                    comparison_data.append({
                        'æ¨¡å‹': model,
                        'å‡†ç¡®ç‡': metric['accuracy'],
                        'å¹³å‡è€—æ—¶(s)': metric['avg_time'],
                        'æµ‹è¯•æ¬¡æ•°': metric['total_tests']
                    })
            
            if comparison_data:
                df = pd.DataFrame(comparison_data)
                st.dataframe(df, use_container_width=True)
                
                # å‡†ç¡®ç‡å¯¹æ¯”å›¾è¡¨
                chart_data = pd.DataFrame({
                    'æ¨¡å‹': [item['æ¨¡å‹'] for item in comparison_data],
                    'å‡†ç¡®ç‡': [item['å‡†ç¡®ç‡'] for item in comparison_data]
                })
                st.bar_chart(chart_data.set_index('æ¨¡å‹'))
        
        with col_stat2:
            st.subheader("é”™è¯¯åˆ†æ")
            error_cases = st.session_state.research_data['error_cases']
            
            if error_cases:
                st.metric("æ€»é”™è¯¯æ¡ˆä¾‹", len(error_cases))
                
                # é”™è¯¯ç±»å‹ç»Ÿè®¡
                error_types = {}
                for case in error_cases[-10:]:  # æ˜¾ç¤ºæœ€è¿‘10ä¸ªé”™è¯¯
                    error_key = f"{case['true_label']}â†’GLM4:{case['glm4_pred']}/è§„åˆ™:{case['rule_pred']}"
                    error_types[error_key] = error_types.get(error_key, 0) + 1
                
                for error_type, count in list(error_types.items())[:5]:
                    st.markdown(f"""
                    <div class="error-analysis">
                        <strong>{error_type}</strong> - {count}æ¬¡
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.success("ğŸ‰ æš‚æ— é”™è¯¯æ¡ˆä¾‹ï¼")
    
    else:
        st.warning("å°šæœªè¿›è¡Œæµ‹è¯•ï¼Œè¯·å…ˆåœ¨ã€Œå®æ—¶å¯¹æ¯”æµ‹è¯•ã€é¡µé¢è¿›è¡Œæµ‹è¯•")

with tab3:
    st.subheader("ğŸ¯ æ ‡å‡†éªŒè¯å®éªŒ")
    
    st.markdown("""
    <div class="research-box">
        <h3>æ ‡å‡†åŒ–æµ‹è¯•é›†éªŒè¯</h3>
        <p>ä½¿ç”¨é¢„å®šä¹‰çš„æ ‡å‡†æµ‹è¯•é›†éªŒè¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("è¿è¡Œæ ‡å‡†æµ‹è¯•é›†éªŒè¯", type="primary"):
        progress_bar = st.progress(0)
        results = []
        
        for i, test_case in enumerate(STANDARD_TEST_SET):
            progress_bar.progress((i + 1) / len(STANDARD_TEST_SET))
            
            # GLM-4åˆ†æ
            glm4_sentiment, glm4_confidence, glm4_time = analyze_sentiment_api(test_case["text"])
            glm4_correct = glm4_sentiment == test_case["true_label"]
            
            # è§„åˆ™æ–¹æ³•åˆ†æ
            rule_sentiment, rule_confidence, rule_time = analyze_sentiment_local(test_case["text"])
            rule_correct = rule_sentiment == test_case["true_label"]
            
            results.append({
                "æµ‹è¯•æ–‡æœ¬": test_case["text"][:20] + "...",
                "çœŸå®æ ‡ç­¾": test_case["true_label"],
                "GLM-4é¢„æµ‹": glm4_sentiment,
                "GLM-4æ­£ç¡®": "âœ…" if glm4_correct else "âŒ",
                "è§„åˆ™æ–¹æ³•é¢„æµ‹": rule_sentiment,
                "è§„åˆ™æ–¹æ³•æ­£ç¡®": "âœ…" if rule_correct else "âŒ"
            })
        
        # æ˜¾ç¤ºç»“æœ
        results_df = pd.DataFrame(results)
        st.dataframe(results_df, use_container_width=True)
        
        # è®¡ç®—å‡†ç¡®ç‡
        glm4_accuracy = sum(1 for r in results if r["GLM-4æ­£ç¡®"] == "âœ…") / len(results)
        rule_accuracy = sum(1 for r in results if r["è§„åˆ™æ–¹æ³•æ­£ç¡®"] == "âœ…") / len(results)
        
        col_acc1, col_acc2 = st.columns(2)
        with col_acc1:
            st.metric("GLM-4æ ‡å‡†é›†å‡†ç¡®ç‡", f"{glm4_accuracy:.1%}")
        with col_acc2:
            st.metric("è§„åˆ™æ–¹æ³•æ ‡å‡†é›†å‡†ç¡®ç‡", f"{rule_accuracy:.1%}")

with tab4:
    st.subheader("ğŸ“ˆ ç ”ç©¶æˆæœåˆ†æ")
    
    st.markdown("""
    <div class="research-box">
        <h3>åŸºäºå®é™…æµ‹è¯•æ•°æ®çš„ç ”ç©¶ç»“è®º</h3>
        <p>æ‰€æœ‰ç»“è®ºå‡æ¥è‡ªç”¨æˆ·æµ‹è¯•ç§¯ç´¯çš„çœŸå®æ•°æ®</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.research_data['test_count'] > 0:
        metrics = st.session_state.research_data['performance_metrics']
        
        col_concl1, col_concl2 = st.columns(2)
        
        with col_concl1:
            st.subheader("ğŸ† ç ”ç©¶å‘ç°")
            
            glm4_acc = metrics['GLM-4']['accuracy']
            rule_acc = metrics['è§„åˆ™æ–¹æ³•']['accuracy']
            glm4_time = metrics['GLM-4']['avg_time']
            rule_time = metrics['è§„åˆ™æ–¹æ³•']['avg_time']
            
            findings = []
            
            if glm4_acc > rule_acc:
                findings.append(f"âœ… **å‡†ç¡®æ€§ä¼˜åŠ¿**: GLM-4æ¯”è§„åˆ™æ–¹æ³•å‡†ç¡®ç‡é«˜ {(glm4_acc-rule_acc):.1%}")
            else:
                findings.append(f"âš ï¸ **æ„å¤–ç»“æœ**: è§„åˆ™æ–¹æ³•è¡¨ç°ä¼˜äºGLM-4")
            
            if rule_time < glm4_time * 100:  # è§„åˆ™æ–¹æ³•å¿«100å€ä»¥ä¸Š
                findings.append(f"âš¡ **é€Ÿåº¦ä¼˜åŠ¿**: è§„åˆ™æ–¹æ³•æ¯”GLM-4å¿« {glm4_time/rule_time:.0f} å€")
            
            if st.session_state.research_data['error_cases']:
                error_rate = len(st.session_state.research_data['error_cases']) / st.session_state.research_data['test_count']
                findings.append(f"ğŸ” **é”™è¯¯æ¨¡å¼**: å‘ç° {len(st.session_state.research_data['error_cases'])} ä¸ªé”™è¯¯æ¡ˆä¾‹ ({error_rate:.1%})")
            
            for finding in findings:
                st.markdown(f"""
                <div class="dynamic-metric">
                    {finding}
                </div>
                """, unsafe_allow_html=True)
        
        with col_concl2:
            st.subheader("ğŸ¯ æŠ€æœ¯é€‰å‹å»ºè®®")
            
            glm4_acc = metrics['GLM-4']['accuracy']
            rule_acc = metrics['è§„åˆ™æ–¹æ³•']['accuracy']
            glm4_time = metrics['GLM-4']['avg_time']
            rule_time = metrics['è§„åˆ™æ–¹æ³•']['avg_time']
            
            if glm4_acc > 0.9 and glm4_time < 3:
                st.success("""
                **æ¨èæ–¹æ¡ˆ: GLM-4 APIè°ƒç”¨**
                - é€‚ç”¨åœºæ™¯: é«˜ç²¾åº¦è¦æ±‚çš„ä¸šåŠ¡åœºæ™¯
                - ä¼˜åŠ¿: å‡†ç¡®ç‡é«˜ï¼Œç†è§£èƒ½åŠ›å¼º
                - æ³¨æ„: APIè°ƒç”¨æˆæœ¬å’Œå“åº”æ—¶é—´
                """)
            
            if rule_acc > 0.7 and rule_time < 0.01:
                st.warning("""
                **å¤‡é€‰æ–¹æ¡ˆ: è§„åˆ™æ–¹æ³•**
                - é€‚ç”¨åœºæ™¯: å®æ—¶æ€§è¦æ±‚é«˜çš„åœºæ™¯
                - ä¼˜åŠ¿: å“åº”æå¿«ï¼Œé›¶æˆæœ¬
                - å±€é™: å‡†ç¡®ç‡ç›¸å¯¹è¾ƒä½
                """)
            
            st.info("""
            **æ··åˆæ–¹æ¡ˆå»ºè®®**
            è§„åˆ™æ–¹æ³•åˆæ­¥è¿‡æ»¤ + GLM-4å¤æ‚æ¡ˆä¾‹ç²¾åˆ¤
            - å¹³è¡¡å‡†ç¡®ç‡å’Œå“åº”é€Ÿåº¦
            - ä¼˜åŒ–æˆæœ¬æ•ˆç›Šæ¯”
            """)
    
    else:
        st.warning("è¯·å…ˆè¿›è¡Œæµ‹è¯•ä»¥ç”Ÿæˆç ”ç©¶æˆæœåˆ†æ")

# é¡µè„š
st.markdown("---")
st.caption("ğŸ”¬ åŠ¨æ€ç ”ç©¶å¹³å° | æ¯æ¬¡æµ‹è¯•éƒ½åœ¨æ¨è¿›ç ”ç©¶è¿›å±• | ä½œè€…: wws")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“š ç ”ç©¶è¯´æ˜")
    st.info("""
    **åŠ¨æ€ç ”ç©¶å¹³å°ç‰¹ç‚¹:**
    - æ‰€æœ‰æ•°æ®æ¥è‡ªå®é™…æµ‹è¯•
    - æŒ‡æ ‡éšæµ‹è¯•ç§¯ç´¯åŠ¨æ€æ›´æ–°
    - çœŸå®åæ˜ æ¨¡å‹æ€§èƒ½
    - æ”¯æŒç ”ç©¶ç»“è®ºç”Ÿæˆ
    """)
    
    st.metric("æ€»æµ‹è¯•æ¬¡æ•°", st.session_state.research_data['test_count'])
    st.metric("ç ”ç©¶å¼€å§‹æ—¶é—´", datetime.now().strftime("%H:%M"))
